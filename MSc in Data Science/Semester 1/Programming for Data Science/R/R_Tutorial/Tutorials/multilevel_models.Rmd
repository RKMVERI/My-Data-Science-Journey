---
title: "Multilevel Models"
author: "Kasper Welbers & Wouter van Atteveldt"
date: "January 2020"
output: 
  html_document:
    toc: yes
editor_options: 
  chunk_output_type: console
---


```{r, echo=F, warning=F, message=F}
knitr::opts_chunk$set(warning=FALSE, message=FALSE, fig.path = "img/")
library(printr)
```

# Multilevel models

Multilevel models are, simply put, linear models that can account for multiple levels in the data. Here we briefly explain what what multilevel analysis in and how to apply it in R with the `lme4` package. 
For tabulating and plotting we'll use the `sjPlot` package.
Also, we could use a bit of tidyverse.

```{r, eval=F}
install.packages("lme4")
install.packages("sjPlot")
```
```{r}
library(lme4)
library(sjPlot)
library(tidyverse)
```

The examples in the lme4 packages use the sleepstudy data, which measures reaction time of participants after sleep deprivation. 
The data contains three variables: Reaction, Days and Subject.
Subjects were limited to 3 hours of sleep each night, so the question is whether their reaction time slows after more days of limited sleep.

```{r}
head(sleepstudy)
```

The sleepstudy data requires multilevel analysis, because the observations are nested in Subjects. 
Linear regression models assume that observations are independent, but that is not the case here.
Different subjects might have different reaction speeds in general, and might also be more or less affected by sleep deprivation. 

To account for this, multilevel models can have `random intercepts` and `random slopes`. By using random intercepts, each Subject has its own intercept, which accounts for differences between subjects in overall reaction speed. Random slopes can be applied for each independent variable in the model, so that each Subject also has its own slope (i.e. coefficient) for this variable. This can be used simply to controll for implications of nested data (to not violate the independence assumption in linear regression). But moreover, it can be used to better investigate variance and effects at different levels. For instance, to what extent student learning success is explained by individual level factors (doing homework, participating in class) or class level factors (class size, experience of teacher).


## Multilevel modeling in R: a visual explanation

We will not try to explain exactly how multilevel modeling works. This is a workshop and several books in its own right. However, after this tutorial you will hopefully understand why its important to properly model data with multiple levels, and realize that it is fairly easy to fit multilevel models in R.

To achieve this, we will show you how to fit a multilevel model, and visually illustrate what the difference is from using a linear model.
For this we'll use a small toy data.frame (which is actually too small to properly fit a multilevel model). 
We'll use the same names as the aforementioned sleep study data for easy interpretation.

```{r}
d = data.frame(Reaction = c(0,1,7,9,17,16,12,10,29,27,24,22,39,36,33,30,49,47,42,42),
               Days = c(1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4),
               Subject = c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5))
```

Here the Subjects have clearly different intercepts (average Reaction) and slopes (effect of Days on Reaction). 
We can show this with a scatterplot, in which different subjects are given different colors.

```{r, lme4demo1}
cols = rainbow(5)  # make colors for 5 subjects
plot(d$Days, d$Reaction, col=cols[d$Subject], pch=16)
```

If we just look at the dots without the colors, we hardly see any patterns. 
Taking the colors into account, we see that the average reaction time (in our toy data) is vastly different for each Subject.
Also, we see that overall the reaction time within Subjects decrease for most Subjects, but with different slopes (the red one even increases).

To show how we can model this with random intercepts and random slopes, we'll fit this data with three models: regular linear model, multilevel model with random intercepts, multilevel model with random intercepts and random slopes. 

### Regular linear model

Let's see what happens if we fit a regular linear regression, and plot the regression line.

```{r}
m = lm(Reaction ~ Days, data=d)
tab_model(m)
```

The model states that there is no relation between Days and Reaction.
We can visualize the problem of fitting a regular linear model to this data by adding the coefficient line to the plot.

```{r lme4demo2}
plot(d$Days, d$Reaction, col=cols[d$Subject], pch=16)
abline(coef(m)[1], coef(m)[2])
```

It does captures the overal pattern (Reaction times goes down), but only roughly. 

### Multilevel model with random intercepts

To fit a linear multilevel model we will use the `lmer` function from the `lme4` package.
Notice the similarity to the `lm` function.
The difference is that you need to specify the higher level in the formula, which looks like this.

```{r}
m_ri = lmer(Reaction ~ Days + (1 | Subject), data=d)
```

The multilevel part is the added `+ (1 | Subject)`. 
The part between the parentheses has two parts:

* The part after the | symbol gives the name of the higher level group, in this case Subject.
* The part before the | specifies the model for this higher level. In the current example, this is only `1`, which referes to the intercept. Normally, the intercept is implicit, but here you do always need to specify it. 

Here we can also use the `screenreg` function (from the `texreg` package) to print the regression table.

```{}
tab_model(m_ri)
```

Interestingly, we see that the intercept and the effect for Days is identical (though now the effect is Days statistically significant). 
This part of the output still shows the overall intercept (or grand intercept) and effect.
What's new is the lower part, which shows the way the model is fit and the random effects.

As with the `glm`, there is no straightforward R2, but sjPlot provides us with a marginal R2 and conditional R2. 
The difference is that the marginal R2 reflects the variance of the fixed effects only, whereas the conditional R2 reflects both the fixed and random effects. 
It is nice to report these, but for multilevel models it is also (more) common and good practice to evalute model fit by comparing different models (as discussed below).

For now, focus on the $\sigma^2$ and $\tau_{00} Subject$ rows.
These report the variance for the individual level (repeated measures of subjects) and group level (subjects), respectively.
We see that the Subject variance (259.00) is much higher than $\sigma^2$ (10.83).
This makes sense for our data, because the biggest differences in the Reaction scores can be explained by the differences between Subjects.
We can see this more clearly by visualizing the effect of Days with the random interceps.
The random intercept values are not reported in the model above, but they are stored in the output (m_ri).

```{r lmer4demo3}
plot(d$Days, d$Reaction, col=cols[d$Subject], pch=16)
for (i in 1:5) {  ## for each subject
  abline(coef(m_ri)$Subject[i,1], coef(m_ri)$Subject[i,2], col=cols[i])
}
```

Now each Subject has it's own regression line for the effect of Days on Reaction. 
This also makes it clear why the variance is mainly on the Subject level. 
The distance of the observations (the dots) to the lines of the same colour is relatively small. 
The bigger distance is between the lines. 

### Multilevel model with random intercepts and random slopes

In the random intercepts model the slope for the effect of Days is still the same.
So now, let's fit the model with random intercepts AND random slopes.
We do this by adding the Days variable in the multilevel part (the part between parentheses) of the formula.

```{r}
m_rs = lmer(Reaction ~ Days + (1 + Days | Subject), data=d)
tab_model(m_rs)
```

(You might get a "Model failed to converge" warning. This is related to the maximum likelihood estimation. Normally you would want to investigate why this happens and fix it. In the current case it is probably related to our very simple and small demo data. Even though it failed to fully converge, it still gives us its the best fit that it did converge to, so for this example we'll ignore the warning.)

Again, the fixed effects for the Intercept and Days are the same. 
What is new is that the variance of $\tau_{11} Subject.Days$ is reported.
This is the variance between Subject in the effect of Days on Reaction.
In our data, this variance is most clearly seen in the effect for the 'red' Subject at the bottom of the graph, which is the only Subject for whom Reaction time somehow increased.

```{r lmer4demo4}
plot(d$Days, d$Reaction, col=cols[d$Subject], pch=16)  ## redo the plot for clarity
for (i in 1:5) {  ## for each subject
  abline(coef(m_rs)$Subject[i,1], coef(m_rs)$Subject[i,2], col=cols[i])
}
```

What we now see is that the random part of the model accounts for the fact that the subjects in our study have (a) a different reaction time overal, and (b) have a different effect of sleep deprivation. 

### Comparing multilevel models

By comparing the models, we can see how the variance at different levels changes.
Here we first make a base model, which is a random intercepts model without any predictor variables.
Then we add Days at the individual level, and finally we add the random slopes for Days.

```{r}
m_base = lmer(Reaction ~ (1 | Subject), data=d)
m1 = lmer(Reaction ~ Days + (1 | Subject), data=d)
m2 = lmer(Reaction ~ Days + (1 + Days| Subject), data=d)
anova(m_base,m1,m2)
```

The anova shows that each model is an improvement of the previous model.
Interestingly, the improvement from m_base to m1 is not that great.
This is because the overall effect of Days (not taking random slopes into account) isn't that great (remember that it was not statistically significant)

```{r}
tab_model(m_base, m1, m2)
```

It's interesting to look at the random effects to see how the variance is explained at different levels.
From m_base to m1 (adding the Days effect) we see that variance is mostly explained at the individual level ($\sigma^2$ decreases from 13.57 to 10.83).
This makes sense, because Days are nested within subjects.
From m1 to m2 (adding the random slope for Days), we see that even more variance at the individual level level is explained.
This again makes sense, because the lines within the Subjects now much better fit the data.


# Another example with more data

This time we'll generate a larger toy dataset about the effects of studying on a student's grade. The multilevel component will be that students are nested in classes, and these classes have different teachers. In addition to a positive effect of studying, we make it so that grades are on average higher if the teacher is better. And to introduce a spurious relation, we'll include a variable for the wealth of students, and make it so that students with more wealth tend to have better teachers. The problem we're aiming for here, is to show that we need to control for the class level differences in average grades, so that we do not incorrectly conclude that being wealthy causes better grades.

The variables in our data are:

* *minutes_studied*: The time a student studied, in minutes (we somehow just know)
* *exam_grade*: A grade on a scale from 1-10
* *wealth*: A continuous variable indicating how wealthy a student is. 
* *class_id*: A factor with class ids, conveniently named after the alphabet (a, b, c, ..., z)
* *teacher_exp*: Teacher experience, measured in number of years.

To generate a dataset with multilevel structure, we'll take the equation for a 2-level model with random intercepts and random slopes. 
This equation is taken from the rather excellent wikipedia page [Multilevel model](https://en.wikipedia.org/wiki/Multilevel_model). If you want more details on the equation (its not critical for this tutorial), please consult sections 1 and 2.

The level 1 regression equation is similar to the equation for single level regression. The difference is the $_j$ subscript which refers to the group index. 

$$ Y_{ij} = \beta_{0j} + \beta_{1j}X_{ij} + e_{ij} $$

The level 2 regression equations have the intercepts and slopes for the level 1 equation as the dependent variable. 

$$ \beta_{0j} = \gamma_{00} + \gamma_{01}W_j + u_{0j}   $$
$$ \beta_{1j} = \gamma_{10} + u_{1j}   $$

The following code is a bit complicated, and you do not need to understand it. 

```{r}
set.seed(1)
groups = 26
groupsize = 30
n = 26*30

level1 = tibble(class_id = rep(letters, each=groupsize),
                hours_studied = rpois(n, 12),
                wealth = rnorm(n, rep(1:groups, each=groupsize), 3))


level2 = tibble(class_id = letters,
                teacher_exp = rpois(groups, 1:groups/2))
level2$B0j = 2 + 0.3*level2$teacher_exp + rnorm(groups, 0, 0.4)
level2$B1j = 0.1 + rnorm(groups, 0, 0.15)

d = left_join(level1, level2, by='class_id')
d$exam_grade = d$B0j + d$B1j*d$hours_studied + rnorm(n, 0, 0.8)
```

## Analyzing the data with normal linear regression

Now that we have our multilevel data, let's first fit the model with linear regression. For good pracice, we'll compare models at different stages of complexity. 

```{r}
m0 = lm(exam_grade ~ 1, data=d)
m1 = lm(exam_grade ~ 1 + hours_studied, data=d)
m2 = lm(exam_grade ~ 1 + hours_studied + wealth, data=d)

tab_model(m0, m1, m2)
anova(m0, m1, m2)
```

### Using dummy variables for class_ids

To be fair, we could address this specific issue with linear regression as well.
By adding the class_id as an independent variable, R will make dummy variables to account for different intercepts of the classes.
After adding these, the effect of wealth will no longer be significant. 
Here we do this, but since this would result in a very long table (25 rows for dummy variables) we'll use the `rm.terms` argument in tab_model to remove these coefficients from the table.
(if you do this, always make sure to clearly report that you did include these dummies, e.g. in a table footnote)

```{r, eval=F}
m3 = lm(exam_grade ~ 1 + hours_studied + wealth + class_id, data=d)
tab_model(m3)
tab_model(m3, rm.terms = paste('class_id', letters, sep=''))
```

Adding dummy variables for groups can be a solution if you do not want to use multilevel models. However, there are stil arguments for why a multilevel model can be a better choice. 
Part of that has to do with how we prefer to think about the effects of groups. 
If there are many groups, then rather than considering them as independent fixed effects, it makes sense to consider the group level differences of the intercept to be drawn from a normal distribution.  
Another benefit of multilevel models is that you can separately look at the explained variance for the first and second level, and can also see whether there is unexplained variance in slopes. 

Finally, the dummy solution becomes problematic if we also want to include other group level effects. In our case, if we actually have data on how experienced teachers are, we could include that in the model to see whether this explains the group level variance. With the dummy solution, this is not possible because all our degrees of freedom for the group have been used, leading to possible biases or even not being able to estimate the other group level coefficient.

In our data, adding the teacher_exp variable results in an NA, due to which we actually cannot use tab_model (which doesn't like NAs). But we can see the problem in the coefficients (we don't show them here because it's messy).

```{r, eval=F}
m3 = lm(exam_grade ~ 1 + hours_studied + wealth + class_id + teacher_exp, data=d)
m3$coefficients
```

## Analyzing the data with multilevel regression 

Now let's do the same with a multilevel mode. 
Let's start with a problem!
If we try to fit our most complex model, we get a warning that the model does not converge

```{r}
m4 = lmer(exam_grade ~ 1 + hours_studied + wealth + teacher_exp + (1 + hours_studied | class_id), data=d)
```

This can be a bit complicated issue (e.g. see [this](https://stats.stackexchange.com/questions/110004/how-scared-should-we-be-about-convergence-warnings-in-lme4) and the top answer]). One solution is centering some of you variables. In our case, the hours_studied and wealth variables have rather high numbers. Here we center them by subtracting the mean, and in our case that solves the issue.

```{f}
hist(d$hours_studied)
d = mutate(d, hours_studied = hours_studied - mean(hours_studied),
              wealth = wealth - mean(wealth))
m4 = lmer(exam_grade ~ 1 + hours_studied + wealth + teacher_exp + (1 + hours_studied | class_id), data=d)
```

Now We can make one big, happy table.
To make it fit on the page, we use the `show.ci = F` argument in tab_model to drop the confidence interval column.

```{r}
m0 = lmer(exam_grade ~ 1 + (1 | class_id), data=d)
m1 = lmer(exam_grade ~ 1 + hours_studied + (1 | class_id), data=d)
m2 = lmer(exam_grade ~ 1 + hours_studied + wealth + (1 | class_id), data=d)
m3 = lmer(exam_grade ~ 1 + hours_studied + wealth + teacher_exp + (1 | class_id), data=d)
m4 = lmer(exam_grade ~ 1 + hours_studied + wealth + teacher_exp + (1 + hours_studied | class_id), data=d)

tab_model(m0, m1, m2, m3, m4, show.ci = F)
anova(m0,m1,m2,m3,m4)
```

First, notice that wealth does not have a significant effect. Even though it is strongly correlated with teacher experience, this variance is much better explained by the random intercepts, as is should be because it is (as we simulated it) the result of teacher experience. 
Second, notice that now we can include teacher experience as an independent (group level) variable, to show that this has a positive effect on exam grade.

In the fourth model we added random slopes for the hours_studied effect, and based on the anova we can conclude that there is notable variance in the effect of hours_studied on exam_grade. 
We don't know what caused this variance (well... we know that we simply added variance when generating the data, but with real data you don't). But knowing that there is variance in the effectiveness of studying with regards to school performance can be important information in itself. Maybe you have, or can collect, data that can explain this, such as what textbooks are used in these classes. 

We can also investigate the random effects to see which classes had on average lower grades, and for which classes the effect of studying was above or below average. 
The versatile plot_model function also has a nice way to visualize this.

```{r lmer_resid_plot}
plot_model(m4, type='re')
```

We've only touched the surface here, but hopefully you see why multilevel modeling is an important technique for working with large, complex datasets. 

## Multilevel Logistic or Poisson regression with glmer()

The `lmer` function can be seen as the `lm` function for multilevel models.
Similarly, the `lme4` package has the `glmer` function, which can be seen as the `glm` function for multilevel models.
In terms of syntax, using `glmer` is very similar to `lmer`, and like in `glm`, you need to specify a `family` (e.g., binomial for logistic regression, poisson for poisson regression).

In other words, if you know GLM and multilevel modeling in R, you're pretty much set to also use Generalized Multilevel Regression Models.

# Knowing what multilevel model to use

This tutorial mainly serves as a general introduction. 
There are many more things that you can do with multilevel models, and many more things to discuss.
If you want to use multilevel modeling, and you're not yet an expert (or don't want to be), a good start is to see what types of models are used in your own field.
And, as always, always try to look around with Google to see if you can find tutorials more specialized to your own field.

To get a gist of the diverse ways in which you can use multilevel models, we recommend [this excellent tutorial] (https://rpsychologist.com/r-guide-longitudinal-lme-lmer). It's mainly written for clinical psychology, but the models can be applied more generally for experimental and other research.